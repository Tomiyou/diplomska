--- a/linux/kernel/bpf/syscall.c
+++ b/linux/kernel/bpf/syscall.c
@@ -1020,6 +1020,31 @@ static void *___bpf_copy_key(bpfptr_t uk
 	return NULL;
 }
 
+bool accel_map_get_fd(int ufd, struct fd *dst)
+{
+	struct bpf_map *map;
+	struct fd f;
+
+	printk("User FD %d\n", ufd);
+	f = fdget(ufd);
+	printk("Kernel FD %p %u\n", f.file, f.flags);
+
+	map = __bpf_map_get(f);
+	dst->file = f.file;
+	dst->flags = f.flags;
+
+	if (IS_ERR(map))
+	{
+		printk("IS ERROR == TRUE\n");
+		return 0;
+	}
+
+	printk("Found map !!!!!\n");
+	return 1;
+}
+
+EXPORT_SYMBOL(accel_map_get_fd);
+
 /* last field in 'union bpf_attr' used by this command */
 #define BPF_MAP_LOOKUP_ELEM_LAST_FIELD flags
 
@@ -1040,7 +1065,9 @@ static int map_lookup_elem(union bpf_att
 	if (attr->flags & ~BPF_F_LOCK)
 		return -EINVAL;
 
+	printk("User FD %d\n", ufd);
 	f = fdget(ufd);
+	printk("Kernel FD %p %u\n", f.file, f.flags);
 	map = __bpf_map_get(f);
 	if (IS_ERR(map))
 		return PTR_ERR(map);
@@ -1087,6 +1114,84 @@ err_put:
 	return err;
 }
 
+int accel_map_lookup_elem(struct fd f, void *key, void *value, u64 flags)
+{
+	struct bpf_map *map;
+
+	/*
+	 *		**BPF_F_LOCK**
+ 	 *			Look up the value of a spin-locked map without
+ 	 *			returning the lock. This must be specified if the
+ 	 *			elements contain a spinlock.
+	*/
+
+	/* Don't need this anymore, we always know it's lookup
+	if (CHECK_ATTR(BPF_MAP_LOOKUP_ELEM))
+		return -EINVAL; */
+
+	if (flags & ~BPF_F_LOCK) {
+		printk("accel_map_lookup_elem: Wrong flag given.\n");
+		return -EINVAL;
+	}
+
+	/* We resolve the kernel map FD at the start instead of each time
+	f = fdget(ufd); */
+	map = __bpf_map_get(f);
+	if (IS_ERR(map)) {
+		printk("accel_map_lookup_elem: Map not found.\n");
+		return PTR_ERR(map);
+	}
+	if (!(map_get_sys_perms(map, f) & FMODE_CAN_READ)) {
+		printk("accel_map_lookup_elem: Map permissions not satisfied.\n");
+		return -EPERM;
+	}
+
+	if ((flags & BPF_F_LOCK) &&
+	    !map_value_has_spin_lock(map)) {
+		printk("accel_map_lookup_elem: Map does NOT have spinlock.\n");
+		return -EINVAL;
+	}
+
+	/* Don't need to copy key from userspace anymore
+	key = __bpf_copy_key(ukey, map->key_size);
+	if (IS_ERR(key)) {
+		err = PTR_ERR(key);
+		goto err_put;
+	} */
+
+	/* Size of value is not needed anymore
+	value_size = bpf_map_value_size(map); */
+
+	/* bpf_map_copy_value should read directly into _value
+	err = -ENOMEM;
+	value = kmalloc(value_size, GFP_USER | __GFP_NOWARN);
+	if (!value)
+		goto free_key; */
+
+	return bpf_map_copy_value(map, key, value, flags);
+	/* Don't need gotos anymore
+	if (err)
+		goto free_value; */
+
+	/* Don't need to copy back to userspace
+	err = -EFAULT;
+	if (copy_to_user(uvalue, value, value_size) != 0)
+		goto free_value; */
+
+	/* err = 0; */
+
+/* No need to free any variables, since they are all
+   owned by the caller
+free_value:
+	kfree(value);
+free_key:
+	kfree(key);
+err_put:
+	fdput(f);
+	return err; */
+}
+
+EXPORT_SYMBOL(accel_map_lookup_elem);
 
 #define BPF_MAP_UPDATE_ELEM_LAST_FIELD flags
 
@@ -1153,6 +1258,84 @@ err_put:
 	return err;
 }
 
+int accel_map_update_elem(struct fd f, void *key, void *_value, u64 flags)
+{
+	bpfptr_t uvalue = make_bpfptr((u64) _value, true);
+	struct bpf_map *map;
+	u32 value_size;
+	void *value;
+	int err;
+
+	/*
+	 *		**BPF_F_LOCK**
+ 	 *			Look up the value of a spin-locked map without
+ 	 *			returning the lock. This must be specified if the
+ 	 *			elements contain a spinlock.
+	*/
+
+	/* Don't need this anymore, we always know it's update
+	if (CHECK_ATTR(BPF_MAP_UPDATE_ELEM))
+		return -EINVAL; */
+
+	/* We resolve the kernel map FD at the start instead of each time
+	f = fdget(ufd); */
+	map = __bpf_map_get(f);
+	if (IS_ERR(map)) {
+		printk("accel_map_update_elem: Map not found.\n");
+		return PTR_ERR(map);
+	}
+	if (!(map_get_sys_perms(map, f) & FMODE_CAN_WRITE)) {
+		printk("accel_map_update_elem: Map permissions not satisfied.\n");
+		return -EPERM;
+	}
+
+	if ((flags & BPF_F_LOCK) &&
+	    !map_value_has_spin_lock(map)) {
+		printk("accel_map_update_elem: Map does NOT have spinlock.\n");
+		return -EINVAL;
+	}
+
+	/* Don't need to copy key from userspace anymore
+	key = ___bpf_copy_key(ukey, map->key_size);
+	if (IS_ERR(key)) {
+		err = PTR_ERR(key);
+		goto err_put;
+	} */
+
+	if (map->map_type == BPF_MAP_TYPE_PERCPU_HASH ||
+	    map->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH ||
+	    map->map_type == BPF_MAP_TYPE_PERCPU_ARRAY ||
+	    map->map_type == BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE)
+		value_size = round_up(map->value_size, 8) * num_possible_cpus();
+	else
+		value_size = map->value_size;
+
+	err = -ENOMEM;
+	value = kmalloc(value_size, __GFP_NOWARN);
+	if (!value)
+		return err;
+
+	err = -EFAULT;
+	if (copy_from_bpfptr(value, uvalue, value_size) != 0) {
+		printk("accel_map_update_elem: copy_from_bpfptr failed.\n");
+		goto free_value;
+	}
+
+	err = bpf_map_update_value(map, f, key, value, flags);
+
+free_value:
+	kfree(value);
+/* No need to free any variables, since they are all
+   owned by the caller
+free_key:
+	kfree(key);
+err_put:
+	fdput(f); */
+	return err;
+}
+
+EXPORT_SYMBOL(accel_map_update_elem);
+
 #define BPF_MAP_DELETE_ELEM_LAST_FIELD key
 
 static int map_delete_elem(union bpf_attr *attr)
@@ -1205,6 +1388,55 @@ err_put:
 	return err;
 }
 
+int accel_map_delete_elem(struct fd f, void *key, u64 flags)
+{
+	struct bpf_map *map;
+	int err;
+
+	/* Don't need this anymore, we always know it's update
+	if (CHECK_ATTR(BPF_MAP_DELETE_ELEM))
+		return -EINVAL; */
+
+	/* We resolve the kernel map FD at the start instead of each time
+	f = fdget(ufd); */
+	map = __bpf_map_get(f);
+	if (IS_ERR(map)) {
+		printk("accel_map_lookup_elem: Map not found.\n");
+		return PTR_ERR(map);
+	}
+	if (!(map_get_sys_perms(map, f) & FMODE_CAN_WRITE)) {
+		printk("accel_map_lookup_elem: Map permissions not satisfied.\n");
+		return -EPERM;
+	}
+
+	/* Don't need to copy key from userspace anymore
+	key = __bpf_copy_key(ukey, map->key_size);
+	if (IS_ERR(key)) {
+		err = PTR_ERR(key);
+		goto err_put;
+	} */
+
+	if (bpf_map_is_dev_bound(map)) {
+		err = bpf_map_offload_delete_elem(map, key);
+		return err;
+	} else if (IS_FD_PROG_ARRAY(map) ||
+		   map->map_type == BPF_MAP_TYPE_STRUCT_OPS) {
+		/* These maps require sleepable context */
+		err = map->ops->map_delete_elem(map, key);
+		return err;
+	}
+
+	bpf_disable_instrumentation();
+	rcu_read_lock();
+	err = map->ops->map_delete_elem(map, key);
+	rcu_read_unlock();
+	bpf_enable_instrumentation();
+	maybe_wait_bpf_programs(map);
+	return err;
+}
+
+EXPORT_SYMBOL(accel_map_delete_elem);
+
 /* last field in 'union bpf_attr' used by this command */
 #define BPF_MAP_GET_NEXT_KEY_LAST_FIELD next_key
 
--- a/linux/include/linux/bpf.h
+++ b/linux/include/linux/bpf.h
@@ -1292,6 +1292,10 @@ struct bpf_map *bpf_map_get_with_uref(u3
 struct bpf_map *__bpf_map_get(struct fd f);
 void bpf_map_inc(struct bpf_map *map);
 void bpf_map_inc_with_uref(struct bpf_map *map);
+bool accel_map_get_fd(int ufd, struct fd *dst);
+int accel_map_lookup_elem(struct fd f, void *key, void *value, u64 flags);
+int accel_map_update_elem(struct fd f, void *key, void *_value, u64 flags);
+int accel_map_delete_elem(struct fd f, void *key, u64 flags);
 struct bpf_map * __must_check bpf_map_inc_not_zero(struct bpf_map *map);
 void bpf_map_put_with_uref(struct bpf_map *map);
 void bpf_map_put(struct bpf_map *map);
